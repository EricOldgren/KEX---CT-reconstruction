{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/KEX---CT-reconstruction\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "GIT_ROOT = Path(\"../..\").resolve()\n",
    "print(GIT_ROOT)\n",
    "SRC = GIT_ROOT / \"src\"\n",
    "if not SRC in sys.path:\n",
    "    sys.path.append(str(SRC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.data import get_htc2022_train_phantoms, get_kits_train_phantoms\n",
    "from utils.polynomials import Chebyshev, Legendre\n",
    "from utils.tools import MSE\n",
    "from geometries import HTC2022_GEOMETRY, CDTYPE, get_moment_mask, DEVICE\n",
    "\n",
    "\n",
    "##CONFIG\n",
    "geometry = HTC2022_GEOMETRY\n",
    "ar = 0.25\n",
    "M, K = 64, 64\n",
    "PolynomialFamily = Legendre\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/KEX---CT-reconstruction/src/explorations/data_process.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223134312e3134382e36372e323039222c2275736572223a227562756e7475227d/home/ubuntu/KEX---CT-reconstruction/src/explorations/data_process.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m##data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223134312e3134382e36372e323039222c2275736572223a227562756e7475227d/home/ubuntu/KEX---CT-reconstruction/src/explorations/data_process.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m kits \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(GIT_ROOT \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdata/kits_phantoms_256.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223134312e3134382e36372e323039222c2275736572223a227562756e7475227d/home/ubuntu/KEX---CT-reconstruction/src/explorations/data_process.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m N, c, h, w \u001b[39m=\u001b[39m kits\u001b[39m.\u001b[39mshape\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223134312e3134382e36372e323039222c2275736572223a227562756e7475227d/home/ubuntu/KEX---CT-reconstruction/src/explorations/data_process.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(kits\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/odl_torch/lib/python3.10/site-packages/torch/serialization.py:777\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m     \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m     \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m     \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m     orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n\u001b[0;32m--> 777\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_reader(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    778\u001b[0m         \u001b[39mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[1;32m    779\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    780\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m dispatching to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (call \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directly to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    781\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m silence this warning)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mUserWarning\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/odl_torch/lib/python3.10/site-packages/torch/serialization.py:282\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name_or_buffer) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     \u001b[39msuper\u001b[39m(_open_zipfile_reader, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileReader(name_or_buffer))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "\n",
    "##data\n",
    "\n",
    "kits = torch.load(GIT_ROOT / \"data/kits_phantoms_256.pt\")\n",
    "N, c, h, w = kits.shape\n",
    "print(kits.shape)\n",
    "kits = kits.reshape((N*c,h,w))\n",
    "resized = torchvision.transforms.functional.resize(kits, (512, 512))\n",
    "print(resized.shape)\n",
    "\n",
    "plt.imshow(resized[700].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sinos computed\n",
      "it: 0 MSE: tensor(142.3576)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "FlatFanBeamGeometry.series_expand() missing 2 required positional arguments: 'PolynomialBasis' and 'n_degs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\salom\\Documents\\code\\KTH\\KEX---CT-reconstruction\\src\\explorations\\data_process.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/salom/Documents/code/KTH/KEX---CT-reconstruction/src/explorations/data_process.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m composed[:, n_known_betas:] \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/salom/Documents/code/KTH/KEX---CT-reconstruction/src/explorations/data_process.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mit:\u001b[39m\u001b[39m\"\u001b[39m, it, \u001b[39m\"\u001b[39m\u001b[39mMSE:\u001b[39m\u001b[39m\"\u001b[39m, MSE(composed, la_sinos))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/salom/Documents/code/KTH/KEX---CT-reconstruction/src/explorations/data_process.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m cn \u001b[39m=\u001b[39m cn \u001b[39m+\u001b[39m geometry\u001b[39m.\u001b[39;49mseries_expand(la_sinos\u001b[39m-\u001b[39;49mcomposed)\n",
      "\u001b[1;31mTypeError\u001b[0m: FlatFanBeamGeometry.series_expand() missing 2 required positional arguments: 'PolynomialBasis' and 'n_degs'"
     ]
    }
   ],
   "source": [
    "sinos = geometry.project_forward(resized)\n",
    "print(\"sinos computed\")\n",
    "la_sinos, knwon_angles = geometry.zero_cropp_sinos(sinos, ar, 0)\n",
    "n_known_betas = geometry.n_known_projections(ar)\n",
    "batch_size = la_sinos.shape[0]\n",
    "\n",
    "n_iters = 30\n",
    "cn = torch.zeros((batch_size, M, K), device=DEVICE, dtype=CDTYPE)\n",
    "mask = get_moment_mask(cn)\n",
    "for it in range(n_iters):\n",
    "    composed = geometry.synthesise_series(cn, PolynomialFamily)\n",
    "    composed[:, n_known_betas:] *= 0\n",
    "    print(\"it:\", it, \"MSE:\", MSE(composed, la_sinos))\n",
    "    cn[:, mask] += geometry.series_expand(la_sinos-composed)[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phantoms = get_htc2022_train_phantoms()\n",
    "print(\"phantoms loaded\")\n",
    "sinos = geometry.project_forward(phantoms)\n",
    "la_sinos, known_angles = geometry.zero_cropp_sinos(sinos, ar, 0)\n",
    "\n",
    "N, Nu, Nb = sinos.shape\n",
    "n_known_u = geometry.n_known_projections(ar)\n",
    "\n",
    "mask = get_moment_mask(torch.zeros((1,M,K)))\n",
    "n_coeffs = mask.sum()\n",
    "print(n_coeffs, M*(M+1)//2)\n",
    "coefficients = torch.zeros((N, n_coeffs), dtype=CDTYPE, requires_grad=False)\n",
    "\n",
    "l1 = 1e-3\n",
    "\n",
    "n_iters = 100\n",
    "\n",
    "for it in range(n_iters):\n",
    "\n",
    "    embedding = torch.zeros((N, M, K), dtype=CDTYPE)\n",
    "    embedding[:, mask] += coefficients\n",
    "    res = geometry.synthesise_series(embedding, Legendre)\n",
    "    loss = MSE(res[:, :n_known_u], la_sinos[:, :n_known_u]) #+ l1*torch.mean(torch.abs(coefficients)**2)\n",
    "\n",
    "    err = la_sinos - res\n",
    "    err[:, n_known_u:] *= 0\n",
    "    coefficients += geometry.series_expand(err, Legendre, M, K)[:, mask]\n",
    "    print(\"iter:\", it, \"loss:\", loss.item())\n",
    "\n",
    "# exp = la_sinos + 0\n",
    "embedding = torch.zeros((N, M, K), dtype=CDTYPE)\n",
    "embedding[:, mask] += coefficients\n",
    "exp = geometry.synthesise_series(embedding, Legendre)\n",
    "recons = geometry.fbp_reconstruct(exp)\n",
    "print(\"exp error:\", MSE(exp, sinos))\n",
    "print(\"recons error:\", MSE(recons, phantoms))\n",
    "\n",
    "disp_ind = 0\n",
    "plt.subplot(121)\n",
    "plt.imshow(sinos[disp_ind])\n",
    "plt.subplot(122)\n",
    "plt.title(\"exp\")\n",
    "plt.imshow(exp[disp_ind].detach())\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(recons[disp_ind])\n",
    "plt.subplot(122)\n",
    "plt.title(\"gt\")\n",
    "plt.imshow(phantoms[disp_ind])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for i in plt.get_fignums():\n",
    "    fig = plt.figure(i)\n",
    "    title = fig._suptitle.get_text() if fig._suptitle is not None else f\"fig{i}\"\n",
    "    plt.savefig(f\"{title}.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KEX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
